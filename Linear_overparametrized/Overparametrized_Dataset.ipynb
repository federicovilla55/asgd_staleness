{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/federicovilla55/optML_mini_project/blob/main/Overparametrized_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NO000Jlxam4"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eT0VZ51xam5",
        "outputId": "281b1637-1180-457f-d996-20faeb23dee1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openml\n",
            "  Downloading openml-0.15.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting liac-arff>=2.4.0 (from openml)\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting xmltodict (from openml)\n",
            "  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: requests in c:\\users\\caspa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openml) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\caspa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openml) (1.6.1)\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\caspa\\appdata\\roaming\\python\\python310\\site-packages (from openml) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\caspa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openml) (2.2.3)\n",
            "Requirement already satisfied: scipy>=0.13.3 in c:\\users\\caspa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openml) (1.15.2)\n",
            "Requirement already satisfied: numpy>=1.6.2 in c:\\users\\caspa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openml) (1.26.4)\n",
            "Collecting minio (from openml)\n",
            "  Downloading minio-7.2.15-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting pyarrow (from openml)\n",
            "  Downloading pyarrow-19.0.1-cp310-cp310-win_amd64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: tqdm in c:\\users\\caspa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openml) (4.67.1)\n",
            "Requirement already satisfied: packaging in c:\\users\\caspa\\appdata\\roaming\\python\\python310\\site-packages (from openml) (24.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\caspa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.0.0->openml) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\caspa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.0.0->openml) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\caspa\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil->openml) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\caspa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=0.18->openml) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\caspa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=0.18->openml) (3.6.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\caspa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from minio->openml) (2025.1.31)\n",
            "Requirement already satisfied: urllib3 in c:\\users\\caspa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from minio->openml) (2.3.0)\n",
            "Requirement already satisfied: argon2-cffi in c:\\users\\caspa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from minio->openml) (23.1.0)\n",
            "Collecting pycryptodome (from minio->openml)\n",
            "  Downloading pycryptodome-3.22.0-cp37-abi3-win_amd64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\caspa\\appdata\\roaming\\python\\python310\\site-packages (from minio->openml) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\caspa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->openml) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\caspa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->openml) (3.10)\n",
            "Requirement already satisfied: colorama in c:\\users\\caspa\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->openml) (0.4.6)\n",
            "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\caspa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from argon2-cffi->minio->openml) (21.2.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\caspa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->minio->openml) (1.17.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\caspa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio->openml) (2.22)\n",
            "Downloading openml-0.15.1-py3-none-any.whl (160 kB)\n",
            "Downloading minio-7.2.15-py3-none-any.whl (95 kB)\n",
            "Downloading pyarrow-19.0.1-cp310-cp310-win_amd64.whl (25.3 MB)\n",
            "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
            "   --- ------------------------------------ 2.4/25.3 MB 11.2 MB/s eta 0:00:03\n",
            "   ------- -------------------------------- 4.5/25.3 MB 12.2 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 7.3/25.3 MB 11.9 MB/s eta 0:00:02\n",
            "   --------------- ------------------------ 10.0/25.3 MB 11.9 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 12.3/25.3 MB 11.9 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 14.7/25.3 MB 12.0 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 17.3/25.3 MB 11.9 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 19.4/25.3 MB 11.8 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 22.0/25.3 MB 11.8 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 24.4/25.3 MB 11.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 25.3/25.3 MB 11.3 MB/s eta 0:00:00\n",
            "Downloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading pycryptodome-3.22.0-cp37-abi3-win_amd64.whl (1.8 MB)\n",
            "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.8/1.8 MB 9.8 MB/s eta 0:00:00\n",
            "Building wheels for collected packages: liac-arff\n",
            "  Building wheel for liac-arff (pyproject.toml): started\n",
            "  Building wheel for liac-arff (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11782 sha256=74ba503cdb3ce8e69ee67eccf7e0f5cbfa4535a3ce9f04e2731446cb14141952\n",
            "  Stored in directory: c:\\users\\caspa\\appdata\\local\\pip\\cache\\wheels\\5d\\2a\\9c\\3895d9617f8f49a0883ba686326d598e78a1c2f54fe3cae86d\n",
            "Successfully built liac-arff\n",
            "Installing collected packages: xmltodict, pycryptodome, pyarrow, liac-arff, minio, openml\n",
            "Successfully installed liac-arff-2.5.0 minio-7.2.15 openml-0.15.1 pyarrow-19.0.1 pycryptodome-3.22.0 xmltodict-0.14.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aJYHzU_AAhji"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from getpass import getpass\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "seed = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GaZmm8oxiek"
      },
      "source": [
        "###GIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-WmfriwCxk2L"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"caspar.amery@gmail.com\"\n",
        "!git config --global user.name \"casparamery\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9SY0W5yxsx6",
        "outputId": "7bad8932-7405-4ac1-a1ff-24069ff314b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your GitHub token: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Cloning into 'optML_mini_project'...\n",
            "remote: Enumerating objects: 289, done.\u001b[K\n",
            "remote: Counting objects: 100% (289/289), done.\u001b[K\n",
            "remote: Compressing objects: 100% (199/199), done.\u001b[K\n",
            "remote: Total 289 (delta 100), reused 270 (delta 86), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (289/289), 7.02 MiB | 25.15 MiB/s, done.\n",
            "Resolving deltas: 100% (100/100), done.\n",
            "/content/optML_mini_project\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ],
      "source": [
        "token = getpass(\"Enter your GitHub token: \")\n",
        "repo_url = f\"https://{token}@github.com/federicovilla55/optML_mini_project.git\"\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd optML_mini_project\n",
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGg9RG5ixuyr",
        "outputId": "6a6f098f-7412-457b-b41f-1e8c9e32294d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n"
          ]
        }
      ],
      "source": [
        "# To create a branch:\n",
        "\n",
        "#!git checkout -b branch_name\n",
        "\n",
        "# Switch to an existing branch:\n",
        "\n",
        "!git checkout main\n",
        "\n",
        "#List all branches:\n",
        "\n",
        "#!git branch\n",
        "\n",
        "#Push a new branch to GitHub (if needed):\n",
        "\n",
        "#!git push -u origin branch_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmt8xFDPxam7"
      },
      "source": [
        "# Dataset Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM37gycl5blM",
        "outputId": "42cfa8de-2e59-4476-fe6f-be95f4c84d4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear shapes: [(79, 110), (79,), (1, 110), (1,), (20, 110), (20,)]\n",
            "Poly-varied shapes: [(79, 110), (79,), (1, 110), (1,), (20, 110), (20,)]\n",
            "Sample feature degrees: [1 3 4 1 2 1 4 3 2 3]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# OVERPARAMETERIZED DATASETS WITH FEATURE BOUNDS [-3, 3]\n",
        "#\n",
        "# Features X are sampled uniformly in [-3, 3], ensuring all inputs\n",
        "# lie within the specified bounds before any polynomial transformations.\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "def create_linear_dataset(n_samples=100, n_features=110, noise=0.0, random_state=None): #Currently noise set to 0\n",
        "    \"\"\"\n",
        "    Overparameterized linear regression dataset:\n",
        "      - X sampled U(-3, 3)\n",
        "      - y = X @ w_true + noise\n",
        "    \"\"\"\n",
        "    rng = np.random.RandomState(random_state)\n",
        "    X = rng.uniform(low=-3, high=3, size=(n_samples, n_features))\n",
        "    w_true = rng.randn(n_features)\n",
        "    y = X.dot(w_true) + noise * rng.randn(n_samples)\n",
        "    return X, y\n",
        "\n",
        "def create_poly_varied_dataset(n_samples=100, n_features=110,\n",
        "                               max_degree=4, noise=0.0, random_state=None): #Currently noise set to 0\n",
        "    \"\"\"\n",
        "    Overparameterized nonlinear regression dataset:\n",
        "      - X sampled U(-3, 3)\n",
        "      - Each feature i raised to its own degree_i ‚àà [1, max_degree]\n",
        "      - y = sum_i w_true[i] * (X[:,i] ** degree_i) + noise\n",
        "    \"\"\"\n",
        "    rng = np.random.RandomState(random_state)\n",
        "    X = rng.uniform(low=-3, high=3, size=(n_samples, n_features))\n",
        "    w_true = rng.randn(n_features)\n",
        "    degrees = rng.randint(1, max_degree + 1, size=n_features)\n",
        "    X_pow = np.zeros_like(X)\n",
        "    for i, d in enumerate(degrees):\n",
        "        X_pow[:, i] = X[:, i] ** d\n",
        "    y = X_pow.dot(w_true) + noise * rng.randn(n_samples)\n",
        "    return X, y, degrees\n",
        "\n",
        "def split_data(X, y, val_size=0.2, test_size=0.2, random_state=None):\n",
        "    \"\"\"\n",
        "    Splits data into train (60%), validation (20%), and test (20%) sets.\n",
        "    \"\"\"\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state)\n",
        "    val_rel = val_size / (1 - test_size)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_temp, y_temp, test_size=val_rel, random_state=random_state)\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "# ------------------------------\n",
        "# Example: generate & split both\n",
        "# ------------------------------\n",
        "# Linear dataset\n",
        "X_lin, y_lin = create_linear_dataset(n_samples=100, n_features=110, noise=0.0,random_state=42)\n",
        "lin_splits = split_data(X_lin, y_lin, val_size=0.01, test_size=0.2, random_state=42) # Overparametrized cases always converge to 0 loss so no need for hyperparameter search!\n",
        "print(\"Linear shapes:\", [arr.shape for arr in lin_splits])\n",
        "\n",
        "# Polynomial-varied dataset\n",
        "X_poly, y_poly, degrees = create_poly_varied_dataset(\n",
        "    n_samples=100, n_features=110, max_degree=4, noise=0.0, random_state=42)\n",
        "poly_splits = split_data(X_poly, y_poly, val_size=0.01, test_size=0.2, random_state=42)  # Overparametrized cases always converge to 0 loss so no need for hyperparameter search!\n",
        "print(\"Poly-varied shapes:\", [arr.shape for arr in poly_splits])\n",
        "print(\"Sample feature degrees:\", degrees[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGtfWTnpcYzJ"
      },
      "source": [
        "# **Linear Case Experiments:**\n",
        "\n",
        "  Gradient Descent convergence\n",
        "\n",
        "Gradient descent on a convex quadratic converges to the global minimizer (here a zero‚Äêloss solution) as long as you pick a step‚Äêsize\n",
        "$$\n",
        "\\eta < \\frac{2}{\\lambda_{\\max}(X^T X)},\n",
        "$$\n",
        "where $\\lambda_{\\max}(X^T X)$ is the largest eigenvalue of $(X^T X)$.\n",
        "In the limit of small enough\n",
        "ùúÇ\n",
        "Œ∑ and enough iterations (full‚Äêbatch GD), you will drive the training loss to (arbitrarily close to) zero.\n",
        "\n",
        "  Training + evaluating all the different kind of regularization\n",
        "\n",
        "  - Baseline\n",
        "  - Dropout\n",
        "  - Weight Decay/L2\n",
        "  - Gradient Noise Injection\n",
        "  - ...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-qArIm2qTEL1"
      },
      "outputs": [],
      "source": [
        "from numpy.linalg import svd\n",
        "\n",
        "X_tr_lin, y_tr_lin, X_val_lin, y_val_lin, X_te_lin, y_te_lin = lin_splits\n",
        "X_comb = np.vstack([X_tr_lin, X_val_lin])\n",
        "y_comb = np.concatenate([y_tr_lin, y_val_lin])\n",
        "n, d = X_comb.shape\n",
        "rng = np.random.RandomState(42)\n",
        "scale = 5   # avoids huge outliers\n",
        "# Amount of initializations\n",
        "init_ws = rng.uniform(-scale, scale, size=(1, d))\n",
        "np.save('linear_init_weights.npy', init_ws)\n",
        "\n",
        "# 3) Compute 95% of max stable step size Œ∑‚Çâ‚ÇÖ\n",
        "_, S_comb, _ = svd(X_comb, full_matrices=False)\n",
        "eta_max = 2.0 / (S_comb[0]**2)\n",
        "eta_95  = 0.95 * eta_max"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIqeF9dEGG2N"
      },
      "source": [
        "###Base line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pCIaYU0zVu2U",
        "outputId": "0d745076-94a9-49ac-c268-b1b7e3ef2566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "=\n",
            "2739.812087470125\n",
            "5000\n",
            "=\n",
            "0.006645278810807602\n",
            "10000\n",
            "=\n",
            "4.4369234540546295e-05\n",
            "15000\n",
            "=\n",
            "6.49119147388956e-07\n",
            "[Init 001/100] ‚Üí Test MSE = 2319.923831\n",
            "\n",
            "Average Test MSE over 100 inits: 2.319924e+03\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import svd\n",
        "def train_linear_gd(X, y, eta, w_init, b_init=0.0,\n",
        "                    max_epochs=20000, tol=1e-8, patience=100):\n",
        "    \"\"\"\n",
        "    Full-batch GD on y = Xw + b with early stopping.\n",
        "    w_init: numpy array of shape (d,)\n",
        "    \"\"\"\n",
        "    n, d = X.shape\n",
        "    w = w_init.copy()\n",
        "    b = b_init\n",
        "    best_loss = np.inf\n",
        "    no_imp = 0\n",
        "    for epoch in range(max_epochs):\n",
        "        preds = X.dot(w) + b\n",
        "        err   = preds - y\n",
        "        loss  = np.mean(err**2)\n",
        "        if epoch % 5000 ==0:\n",
        "            print(epoch)\n",
        "            print(\"=\")\n",
        "            print(loss)\n",
        "        # Early stop check\n",
        "        if loss + tol < best_loss:\n",
        "            best_loss, no_imp = loss, 0\n",
        "        else:\n",
        "            no_imp += 1\n",
        "        if best_loss < tol or no_imp >= patience:\n",
        "            break\n",
        "        # Gradients\n",
        "        grad_w = (2.0 / n) * X.T.dot(err)\n",
        "        grad_b = (2.0 / n) * np.sum(err)\n",
        "        # Update\n",
        "        w -= eta * grad_w\n",
        "        b -= eta * grad_b\n",
        "    return w, b\n",
        "\n",
        "def mse_loss(X, y, w, b):\n",
        "    \"\"\"Mean squared error.\"\"\"\n",
        "    return np.mean((X.dot(w) + b - y)**2)\n",
        "\n",
        "\n",
        "# 6) Loop over all 100 initializations\n",
        "test_losses = []\n",
        "for idx, w0 in enumerate(init_ws, start=1):\n",
        "    # train from this initialization\n",
        "    w_star, b_star = train_linear_gd(X_comb, y_comb, eta_95, w_init=w0, b_init=0.0)\n",
        "    # evaluate on test set\n",
        "    test_mse = mse_loss(X_te_lin, y_te_lin, w_star, b_star)\n",
        "    test_losses.append(test_mse)\n",
        "    print(f\"[Init {idx:03d}/100] ‚Üí Test MSE = {test_mse:.6f}\")\n",
        "\n",
        "# 7) Average test loss\n",
        "avg_mse = np.mean(test_losses)\n",
        "print(f\"\\nAverage Test MSE over 100 inits: {avg_mse:.6e}\")\n",
        "\n",
        "# init_ws is stored in 'linear_init_weights.npy' for later reuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W619gwRHH3Ue"
      },
      "source": [
        "### ASGD case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSCOhXMFH5rR",
        "outputId": "6f610ebc-962b-4a6e-a229-272ff83cdd81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1] Train MSE = 6.161611e+02\n",
            "[Epoch 2] Train MSE = 2.806573e+02\n",
            "[Epoch 3] Train MSE = 1.898026e+02\n",
            "[Epoch 4] Train MSE = 8.408646e+01\n",
            "[Epoch 5] Train MSE = 2.402593e+01\n",
            "[Epoch 6] Train MSE = 1.411208e+01\n",
            "[Epoch 7] Train MSE = 6.994892e+00\n",
            "[Epoch 8] Train MSE = 4.270392e+00\n",
            "[Epoch 9] Train MSE = 2.833372e+00\n",
            "[Epoch 10] Train MSE = 1.907298e+00\n",
            "[Epoch 11] Train MSE = 1.282774e+00\n",
            "[Epoch 12] Train MSE = 9.800470e-01\n",
            "[Epoch 13] Train MSE = 7.313037e-01\n",
            "[Epoch 14] Train MSE = 5.415344e-01\n",
            "[Epoch 15] Train MSE = 3.803157e-01\n",
            "[Epoch 16] Train MSE = 2.975742e-01\n",
            "[Epoch 17] Train MSE = 2.258846e-01\n",
            "[Epoch 18] Train MSE = 1.780057e-01\n",
            "[Epoch 19] Train MSE = 1.427797e-01\n",
            "[Epoch 20] Train MSE = 1.152652e-01\n",
            "[Epoch 21] Train MSE = 8.474092e-02\n",
            "[Epoch 22] Train MSE = 6.770584e-02\n",
            "[Epoch 23] Train MSE = 5.234907e-02\n",
            "[Epoch 24] Train MSE = 4.034205e-02\n",
            "[Epoch 25] Train MSE = 3.192861e-02\n",
            "[Epoch 26] Train MSE = 2.625798e-02\n",
            "[Epoch 27] Train MSE = 2.196052e-02\n",
            "[Epoch 28] Train MSE = 1.788813e-02\n",
            "[Epoch 29] Train MSE = 1.402755e-02\n",
            "[Epoch 30] Train MSE = 1.043127e-02\n",
            "[Epoch 31] Train MSE = 7.867171e-03\n",
            "[Epoch 32] Train MSE = 6.604252e-03\n",
            "[Epoch 33] Train MSE = 5.565841e-03\n",
            "[Epoch 34] Train MSE = 4.363244e-03\n",
            "[Epoch 35] Train MSE = 3.665419e-03\n",
            "[Epoch 36] Train MSE = 3.050760e-03\n",
            "[Epoch 37] Train MSE = 2.410340e-03\n",
            "[Epoch 38] Train MSE = 1.836315e-03\n",
            "[Epoch 39] Train MSE = 1.493727e-03\n",
            "[Epoch 40] Train MSE = 1.264621e-03\n",
            "[Epoch 41] Train MSE = 1.071138e-03\n",
            "[Epoch 42] Train MSE = 9.162944e-04\n",
            "[Epoch 43] Train MSE = 7.209259e-04\n",
            "[Epoch 44] Train MSE = 5.615996e-04\n",
            "[Epoch 45] Train MSE = 4.449303e-04\n",
            "[Epoch 46] Train MSE = 3.282171e-04\n",
            "[Epoch 47] Train MSE = 2.511756e-04\n",
            "[Epoch 48] Train MSE = 2.044828e-04\n",
            "[Epoch 49] Train MSE = 1.645648e-04\n",
            "[Epoch 50] Train MSE = 1.221644e-04\n",
            "[Epoch 51] Train MSE = 9.546596e-05\n",
            "[Epoch 52] Train MSE = 7.639242e-05\n",
            "[Epoch 53] Train MSE = 6.598039e-05\n",
            "[Epoch 54] Train MSE = 5.229614e-05\n",
            "[Epoch 55] Train MSE = 4.122228e-05\n",
            "[Epoch 56] Train MSE = 3.294444e-05\n",
            "[Epoch 57] Train MSE = 2.635106e-05\n",
            "[Epoch 58] Train MSE = 2.105140e-05\n",
            "[Epoch 59] Train MSE = 1.650866e-05\n",
            "[Epoch 60] Train MSE = 1.354130e-05\n",
            "[Epoch 61] Train MSE = 1.009236e-05\n",
            "[Epoch 62] Train MSE = 9.067854e-06\n",
            "[Epoch 63] Train MSE = 8.086504e-06\n",
            "[Epoch 64] Train MSE = 6.930246e-06\n",
            "[Epoch 65] Train MSE = 5.839255e-06\n",
            "[Epoch 66] Train MSE = 4.610310e-06\n",
            "[Epoch 67] Train MSE = 3.729030e-06\n",
            "[Epoch 68] Train MSE = 3.084120e-06\n",
            "[Epoch 69] Train MSE = 2.473731e-06\n",
            "[Epoch 70] Train MSE = 2.094738e-06\n",
            "[Epoch 71] Train MSE = 1.877475e-06\n",
            "[Epoch 72] Train MSE = 1.558760e-06\n",
            "[Epoch 73] Train MSE = 1.223266e-06\n",
            "[Epoch 74] Train MSE = 9.690558e-07\n",
            "[Epoch 75] Train MSE = 8.103022e-07\n",
            "Worker 0 exiting\n",
            "Worker 8 exitingWorker 9 exitingWorker 4 exitingWorker 7 exiting\n",
            "\n",
            "\n",
            "\n",
            "Worker 1 exiting\n",
            "Worker 6 exitingWorker 3 exiting\n",
            "\n",
            "Worker 5 exitingWorker 2 exiting\n",
            "\n",
            "\n",
            "ASGD Test MSE = 3.563503e+02\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "def asgd_worker(rank, model, optimizer, shared, train_dataset,\n",
        "                batch_size, max_epochs, max_no_improve, epsilon, device):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    for epoch in range(max_epochs):\n",
        "        if shared.stop:\n",
        "            break\n",
        "        # one epoch of Hogwild SGD updates\n",
        "        for Xb, yb in train_loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(Xb)         # preds.shape = [batch, 1]\n",
        "            loss = nn.MSELoss()(preds, yb)  # yb.shape = [batch, 1]\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        # rank 0 worker does early‚Äêstop check\n",
        "        if rank == 0:\n",
        "            total_loss = 0.0\n",
        "            count = 0\n",
        "            for Xall, yall in DataLoader(train_dataset, batch_size=batch_size):\n",
        "                Xall, yall = Xall.to(device), yall.to(device)\n",
        "                with torch.no_grad():\n",
        "                    pred = model(Xall)\n",
        "                    total_loss += nn.MSELoss(reduction='sum')(pred, yall).item()\n",
        "                count += yall.size(0)\n",
        "            train_mse = total_loss / count\n",
        "            print(f\"[Epoch {epoch+1}] Train MSE = {train_mse:.6e}\")\n",
        "            if train_mse + epsilon < shared.best_loss:\n",
        "                shared.best_loss = train_mse\n",
        "                shared.epochs_no_improve = 0\n",
        "            else:\n",
        "                shared.epochs_no_improve += 1\n",
        "            if shared.best_loss < epsilon or shared.epochs_no_improve >= max_no_improve:\n",
        "                shared.stop = True\n",
        "    print(f\"Worker {rank} exiting\")\n",
        "\n",
        "\n",
        "def train_asgd_linear(w0,lin_splits, workers=1, max_epochs=100000,\n",
        "                      max_no_improve=1000, epsilon=1e-6, device='cpu'):\n",
        "    # unpack & combine train+val, and UNIFY target shapes to [N,1]\n",
        "    X_tr, y_tr, X_val, y_val, X_te, y_te = lin_splits\n",
        "    X_comb = np.vstack([X_tr, X_val])\n",
        "    y_comb = np.concatenate([y_tr, y_val])[:, None]  # now shape (N,1)\n",
        "    train_ds = TensorDataset(torch.from_numpy(X_comb).float(),\n",
        "                             torch.from_numpy(y_comb).float())\n",
        "    test_ds  = TensorDataset(torch.from_numpy(X_te).float(),\n",
        "                             torch.from_numpy(y_te[:, None]).float())\n",
        "\n",
        "    # compute eta_95\n",
        "    U, S, _ = np.linalg.svd(X_comb, full_matrices=False)\n",
        "    eta_95 = 0.95 * (2.0 / (S[0]**2))\n",
        "\n",
        "    # model & optimizer\n",
        "    input_dim = X_comb.shape[1]\n",
        "    model = nn.Linear(input_dim, 1, bias=True)\n",
        "    model.share_memory()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=eta_95)\n",
        "\n",
        "    # shared state\n",
        "    manager = mp.Manager()\n",
        "    shared = manager.Namespace()\n",
        "    shared.best_loss = float('inf')\n",
        "    shared.epochs_no_improve = 0\n",
        "    shared.stop = False\n",
        "\n",
        "    mp.set_start_method('fork', force=True)\n",
        "\n",
        "    batch_size = X_comb.shape[0] # Full batch\n",
        "    processes = []\n",
        "    for rank in range(workers):\n",
        "        p = mp.Process(\n",
        "            target=asgd_worker,\n",
        "            args=(\n",
        "                rank, model, optimizer, shared,\n",
        "                train_ds, batch_size,\n",
        "                max_epochs, max_no_improve, epsilon, device\n",
        "            )\n",
        "        )\n",
        "        p.start()\n",
        "        processes.append(p)\n",
        "\n",
        "    for p in processes:\n",
        "        p.join()\n",
        "\n",
        "    # test evaluation\n",
        "    model.eval()\n",
        "    total_te = 0.0\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in DataLoader(test_ds, batch_size=batch_size):\n",
        "            preds = model(Xb.to(device))\n",
        "            total_te += nn.MSELoss(reduction='sum')(preds, yb.to(device)).item()\n",
        "    test_mse = total_te / len(test_ds)\n",
        "    print(f\"\\nASGD Test MSE = {test_mse:.6e}\")\n",
        "    return model, test_mse\n",
        "\n",
        "\n",
        "workers = 10\n",
        "test_losses = []\n",
        "for idx, w0 in enumerate(init_ws, start=1):\n",
        "    trained_asgd, test_mse = train_asgd_linear(w0,lin_splits, workers)\n",
        "    test_losses.append(test_mse)\n",
        "    print(f\"[Init {idx:03d}/100] ‚Üí Test MSE = {test_mse:.6e}\")\n",
        "\n",
        "# 7) Average test loss\n",
        "avg_mse = np.mean(test_losses)\n",
        "print(f\"\\nAverage Test MSE over 100 inits: {avg_mse:.6e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6KvDCnINjgZ"
      },
      "source": [
        "# **Non-Linear Case Experiments:**\n",
        "  Training + evaluating all the different kind of regularization\n",
        "\n",
        "  - Baseline\n",
        "  - Dropout\n",
        "  - Weight Decay/L2\n",
        "  - Gradient Noise Injection\n",
        "  - ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISS8LfWhNrNH"
      },
      "source": [
        "###Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkAPZuaSNmKS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Helper: select activation\n",
        "def get_activation_fn(name: str):\n",
        "    name = name.lower()\n",
        "    if name == 'relu':\n",
        "        return nn.ReLU()\n",
        "    elif name == 'sigmoid':\n",
        "        return nn.Sigmoid()\n",
        "    elif name == 'tanh':\n",
        "        return nn.Tanh()\n",
        "    elif name == 'linear':\n",
        "        return nn.Identity()\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported activation. Choose from 'relu','sigmoid','tanh','linear'.\")\n",
        "\n",
        "# Linear regression model\n",
        "class LinearModel(nn.Module):\n",
        "    def __init__(self, input_dim, bias=True):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1, bias=bias)\n",
        "    def forward(self, x):\n",
        "        return self.linear(x).squeeze(-1)  # shape: (batch,)\n",
        "\n",
        "# MLP for nonlinear cases\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_layers=1, hidden_units=64, activation='relu', bias=True):\n",
        "        \"\"\"\n",
        "        input_dim: number of features\n",
        "        hidden_layers: number of hidden layers\n",
        "        hidden_units: units per hidden layer\n",
        "        activation: nonlinearity name\n",
        "        bias: whether to use bias terms\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        act_fn = get_activation_fn(activation)\n",
        "        layers = []\n",
        "        in_dim = input_dim\n",
        "        for _ in range(hidden_layers):\n",
        "            layers.append(nn.Linear(in_dim, hidden_units, bias=bias))\n",
        "            layers.append(act_fn)\n",
        "            in_dim = hidden_units\n",
        "        layers.append(nn.Linear(in_dim, 1, bias=bias))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x).squeeze(-1)\n",
        "\n",
        "# Training loop for regression (MSE)\n",
        "def train_model(model, optimizer, data_loader, epoch, num_epochs, grad_noise_std=0.0, device='cpu'):\n",
        "    model.train()\n",
        "    criterion = nn.MSELoss()\n",
        "    running_loss = 0.0\n",
        "    for X_batch, y_batch in tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(X_batch)\n",
        "        loss = criterion(preds, y_batch)\n",
        "        loss.backward()\n",
        "        # optional gradient noise\n",
        "        if grad_noise_std > 0:\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters():\n",
        "                    if p.grad is not None:\n",
        "                        p.grad.add_(torch.randn_like(p.grad) * grad_noise_std)\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * X_batch.size(0)\n",
        "    return running_loss / len(data_loader.dataset)\n",
        "\n",
        "# Evaluation loop (MSE)\n",
        "def evaluate_model(model, data_loader, device='cpu'):\n",
        "    model.eval()\n",
        "    criterion = nn.MSELoss(reduction='sum')\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            preds = model(X_batch)\n",
        "            total_loss += criterion(preds, y_batch).item()\n",
        "    return total_loss / len(data_loader.dataset)\n",
        "\n",
        "# Run experiment wrapper\n",
        "def run_experiment(name, train_data, val_data, test_data,\n",
        "                   model_ctor, model_kwargs,\n",
        "                   learning_rate=1e-3, weight_decay=0.0,\n",
        "                   batch_size=64, epochs=50, grad_noise_std=0.0,\n",
        "                   device='cpu'):\n",
        "    print(f\"\\n=== Experiment: {name} ===\")\n",
        "    # DataLoaders\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    val_loader   = DataLoader(val_data,   batch_size=batch_size, shuffle=False)\n",
        "    test_loader  = DataLoader(test_data,  batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = model_ctor(**model_kwargs).to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    start = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = train_model(model, optimizer, train_loader, epoch, epochs, grad_noise_std, device)\n",
        "        val_loss = evaluate_model(model, val_loader, device)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Train MSE: {train_loss:.4f}, Val MSE: {val_loss:.4f}\")\n",
        "    duration = time.time() - start\n",
        "    print(f\"Training finished in {duration:.1f}s\")\n",
        "\n",
        "    test_loss = evaluate_model(model, test_loader, device)\n",
        "    print(f\"Test MSE: {test_loss:.4f}\")\n",
        "    return model, train_losses, val_losses, test_loss\n",
        "\n",
        "# ASGD (Hogwild!) worker\n",
        "def train_worker(rank, shared_model, optimizer, dataset, epochs, batch_size, grad_noise_std, device):\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    shared_model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        for X_batch, y_batch in loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = nn.MSELoss()(shared_model(X_batch), y_batch)\n",
        "            loss.backward()\n",
        "            if grad_noise_std > 0:\n",
        "                with torch.no_grad():\n",
        "                    for p in shared_model.parameters():\n",
        "                        if p.grad is not None:\n",
        "                            p.grad.add_(torch.randn_like(p.grad) * grad_noise_std)\n",
        "            optimizer.step()\n",
        "        print(f\"Worker {rank} completed epoch {epoch+1}\")\n",
        "\n",
        "def run_asgd(model_ctor, model_kwargs, train_data, learning_rate=1e-3,\n",
        "             batch_size=64, workers=4, epochs=10, grad_noise_std=0.0, device='cpu'):\n",
        "    model = model_ctor(**model_kwargs)\n",
        "    model.share_memory()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    import torch.multiprocessing as mp\n",
        "    processes = []\n",
        "    epochs_per_worker = epochs\n",
        "    for rank in range(workers):\n",
        "        p = mp.Process(target=train_worker,\n",
        "                       args=(rank, model, optimizer, train_data, epochs_per_worker, batch_size, grad_noise_std, device))\n",
        "        p.start()\n",
        "        processes.append(p)\n",
        "    for p in processes:\n",
        "        p.join()\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqM-v7eWOKc0"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_s8DEZDOK4n"
      },
      "source": [
        "## **Hyperparameter tuning for baseline**\n",
        "\n",
        "Functions have to be changed !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEcTiAhOOK4o"
      },
      "source": [
        "Using Keras for this because its interface is easier for this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5rUTeIEmOK4o",
        "outputId": "bb83b167-6580-4bdf-e69c-fb9356fd9abe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras_core\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras_core) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras_core) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras_core) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras_core) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras_core) (3.13.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from keras_core) (0.1.9)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->keras_core) (25.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree->keras_core) (1.17.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras_core) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras_core) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras_core) (0.1.2)\n",
            "Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras_core\n",
            "Successfully installed keras_core-0.1.7\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.13.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_core\n",
        "!pip install keras-tuner --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzG24LaAOK4p"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "import keras_core as keras\n",
        "#########################################\n",
        "import tensorflow as tf\n",
        "#from tensorflow.keras.optimizers import Adadelta\n",
        "import keras\n",
        "#from tensorflow.keras import layers\n",
        "#from tensorflow.keras.optimizers import Adam\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras import regularizers\n",
        "#import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "#from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import clone_model\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "jPeqcIbvPXC7"
      },
      "outputs": [],
      "source": [
        "X_train_poly, y_train_poly, X_val_poly, y_val_poly, X_test_poly, y_test_poly = poly_splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxpQCmZeOK4r",
        "outputId": "6adc1586-d4c0-45e2-c9d4-c7ca569b01bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reloading Tuner from /content/optML_mini_project/Hyperparam Search Baseline Model For Linear Overparametrized/tuner0.json\n"
          ]
        }
      ],
      "source": [
        "# Define the model as a function for Keras Tuner for regression\n",
        "def build_model(hp):\n",
        "    net = keras.Sequential()\n",
        "\n",
        "    # Input layer\n",
        "    net.add(keras.layers.Input(shape=(X_train_poly.shape[1],)))\n",
        "\n",
        "    # Define the activation function to be used for all layers\n",
        "    activation_function = hp.Choice('activation_function', ['relu', 'tanh', 'sigmoid'])\n",
        "\n",
        "    # No regularization in base line\n",
        "    #regularization = hp.Float('regularization', min_value=0.0, max_value=0.1, step=0.005)\n",
        "\n",
        "    # Tune the number of hidden layers\n",
        "    for i in range(hp.Int('hidden_layers', 2, 5)):\n",
        "        # Tune the number of units per layer\n",
        "        units = hp.Int(f'units_in_layer{i}', min_value=32, max_value=256, step=32)\n",
        "        net.add(keras.layers.Dense(units=units, activation= activation_function, kernel_regularizer=regularizers.l2(0)))\n",
        "\n",
        "    # Output layer\n",
        "    net.add(keras.layers.Dense(units=1, activation= activation_function))\n",
        "\n",
        "    net.compile(\n",
        "        optimizer=keras.optimizers.SGD(learning_rate=hp.Float('learning_rate', 1e-3, 1e-1, sampling='log')),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "        )\n",
        "    return net\n",
        "\n",
        "# Define the tuner\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',  # Optimize for validation loss, not accuracy in regression\n",
        "    max_trials=100,         # Number of hyperparameter combinations to try\n",
        "    executions_per_trial=1, # Number of times to train each configuration\n",
        "    directory='/content/optML_mini_project',\n",
        "    project_name='Hyperparam Search Baseline Model For Non Linear Overparametrized'\n",
        ")\n",
        "\n",
        "# Define the EarlyStopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',       # Monitor validation loss for early stopping\n",
        "    patience=5,               # Number of epochs with no improvement before stopping\n",
        "    restore_best_weights=True # Restore model weights from the epoch with the best validation loss\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_J0hF46OK4r"
      },
      "source": [
        "**Only run this cell if want training/search again => THIS CAN TAKE A LONG TIME**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7hCLYcIOK4s",
        "outputId": "03e27262-44db-4975-93cf-2f56045d12c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 250 Complete [00h 00m 05s]\n",
            "val_loss: 1600.9865112304688\n",
            "\n",
            "Best val_loss So Far: 1409.7673950195312\n",
            "Total elapsed time: 00h 21m 31s\n"
          ]
        }
      ],
      "source": [
        "# Run tuner search with custom loss history and early stopping\n",
        "for trial_id in range(tuner.oracle.max_trials):\n",
        "    tuner.search(\n",
        "        X_train_poly, y_train_poly,\n",
        "        validation_data=(X_val_poly, y_val_poly),\n",
        "        epochs=50,\n",
        "        batch_size=20,\n",
        "        callbacks=[early_stopping]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MnD189nPOK4t",
        "outputId": "c1bbe16d-7a80-48f2-8e0c-dac1eb7669de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 1\n",
            "learning_rate (Float)\n",
            "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.1, 'step': None, 'sampling': 'log'}\n",
            "Results summary\n",
            "Results in /content/optML_mini_project/Hyperparam Search Baseline Model For Linear Overparametrized\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_loss\", direction=\"min\")\n",
            "\n",
            "Trial 045 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.010881800788534846\n",
            "Score: 1409.7673950195312\n",
            "\n",
            "Trial 028 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.016459331291952827\n",
            "Score: 1433.366943359375\n",
            "\n",
            "Trial 024 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.01411254804624754\n",
            "Score: 1434.1825561523438\n",
            "\n",
            "Trial 217 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.013233340167603112\n",
            "Score: 1439.9340209960938\n",
            "\n",
            "Trial 092 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.015256589990246058\n",
            "Score: 1443.3583984375\n",
            "\n",
            "Trial 179 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.001595935236110003\n",
            "Score: 1444.2477416992188\n",
            "\n",
            "Trial 242 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.01634224658884753\n",
            "Score: 1446.4083251953125\n",
            "\n",
            "Trial 056 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.011363871072843399\n",
            "Score: 1447.6484985351562\n",
            "\n",
            "Trial 004 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.01973462907005616\n",
            "Score: 1448.198486328125\n",
            "\n",
            "Trial 216 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.01172501649121111\n",
            "Score: 1453.911376953125\n"
          ]
        }
      ],
      "source": [
        "# Print the summary of the search space\n",
        "tuner.search_space_summary()\n",
        "\n",
        "# Print the results of the search\n",
        "tuner.results_summary()                       #WILL RETURN WRONG LAYER SIZES!!!! STARTS OF RIGHT, BUT FILLED WITH ADDITIONAL BS => check amount of layers it says there is"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5zUsePTOK4t"
      },
      "source": [
        "Save results in GIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBLvcqhVOK4u",
        "outputId": "b7166673-efb0-4ac9-c356-426ac7514d69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\content\\optML_mini_project\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ],
      "source": [
        "%cd /content/optML_mini_project\n",
        "!git add --a\n",
        "!git commit -m \"Hyperparameter search for linear baseline model\"\n",
        "!git push"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "sszxTJbnOK4u",
        "outputId": "25db68ff-8593-4ff6-dc05-28c26a7c1250"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model 1 Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              ‚îÇ           \u001b[38;5;34m501\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model 2 Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              ‚îÇ           \u001b[38;5;34m501\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model 3 Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              ‚îÇ           \u001b[38;5;34m501\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model 4 Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              ‚îÇ           \u001b[38;5;34m501\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model 5 Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              ‚îÇ           \u001b[38;5;34m501\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model 6 Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              ‚îÇ           \u001b[38;5;34m501\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model 7 Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              ‚îÇ           \u001b[38;5;34m501\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model 8 Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              ‚îÇ           \u001b[38;5;34m501\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model 9 Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              ‚îÇ           \u001b[38;5;34m501\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model 10 Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              ‚îÇ           \u001b[38;5;34m501\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> (1.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m501\u001b[0m (1.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model 1 Optimizer:\n",
            "  name: SGD\n",
            "  learning_rate: 0.010881801135838032\n",
            "  weight_decay: None\n",
            "  clipnorm: None\n",
            "  global_clipnorm: None\n",
            "  clipvalue: None\n",
            "  use_ema: False\n",
            "  ema_momentum: 0.99\n",
            "  ema_overwrite_frequency: None\n",
            "  loss_scale_factor: None\n",
            "  gradient_accumulation_steps: None\n",
            "  momentum: 0.0\n",
            "  nesterov: False\n",
            "\n",
            "Model 2 Optimizer:\n",
            "  name: SGD\n",
            "  learning_rate: 0.016459330916404724\n",
            "  weight_decay: None\n",
            "  clipnorm: None\n",
            "  global_clipnorm: None\n",
            "  clipvalue: None\n",
            "  use_ema: False\n",
            "  ema_momentum: 0.99\n",
            "  ema_overwrite_frequency: None\n",
            "  loss_scale_factor: None\n",
            "  gradient_accumulation_steps: None\n",
            "  momentum: 0.0\n",
            "  nesterov: False\n",
            "\n",
            "Model 3 Optimizer:\n",
            "  name: SGD\n",
            "  learning_rate: 0.014112547971308231\n",
            "  weight_decay: None\n",
            "  clipnorm: None\n",
            "  global_clipnorm: None\n",
            "  clipvalue: None\n",
            "  use_ema: False\n",
            "  ema_momentum: 0.99\n",
            "  ema_overwrite_frequency: None\n",
            "  loss_scale_factor: None\n",
            "  gradient_accumulation_steps: None\n",
            "  momentum: 0.0\n",
            "  nesterov: False\n",
            "\n",
            "Model 4 Optimizer:\n",
            "  name: SGD\n",
            "  learning_rate: 0.013233340345323086\n",
            "  weight_decay: None\n",
            "  clipnorm: None\n",
            "  global_clipnorm: None\n",
            "  clipvalue: None\n",
            "  use_ema: False\n",
            "  ema_momentum: 0.99\n",
            "  ema_overwrite_frequency: None\n",
            "  loss_scale_factor: None\n",
            "  gradient_accumulation_steps: None\n",
            "  momentum: 0.0\n",
            "  nesterov: False\n",
            "\n",
            "Model 5 Optimizer:\n",
            "  name: SGD\n",
            "  learning_rate: 0.015256590209901333\n",
            "  weight_decay: None\n",
            "  clipnorm: None\n",
            "  global_clipnorm: None\n",
            "  clipvalue: None\n",
            "  use_ema: False\n",
            "  ema_momentum: 0.99\n",
            "  ema_overwrite_frequency: None\n",
            "  loss_scale_factor: None\n",
            "  gradient_accumulation_steps: None\n",
            "  momentum: 0.0\n",
            "  nesterov: False\n",
            "\n",
            "Model 6 Optimizer:\n",
            "  name: SGD\n",
            "  learning_rate: 0.001595935202203691\n",
            "  weight_decay: None\n",
            "  clipnorm: None\n",
            "  global_clipnorm: None\n",
            "  clipvalue: None\n",
            "  use_ema: False\n",
            "  ema_momentum: 0.99\n",
            "  ema_overwrite_frequency: None\n",
            "  loss_scale_factor: None\n",
            "  gradient_accumulation_steps: None\n",
            "  momentum: 0.0\n",
            "  nesterov: False\n",
            "\n",
            "Model 7 Optimizer:\n",
            "  name: SGD\n",
            "  learning_rate: 0.016342246904969215\n",
            "  weight_decay: None\n",
            "  clipnorm: None\n",
            "  global_clipnorm: None\n",
            "  clipvalue: None\n",
            "  use_ema: False\n",
            "  ema_momentum: 0.99\n",
            "  ema_overwrite_frequency: None\n",
            "  loss_scale_factor: None\n",
            "  gradient_accumulation_steps: None\n",
            "  momentum: 0.0\n",
            "  nesterov: False\n",
            "\n",
            "Model 8 Optimizer:\n",
            "  name: SGD\n",
            "  learning_rate: 0.011363871395587921\n",
            "  weight_decay: None\n",
            "  clipnorm: None\n",
            "  global_clipnorm: None\n",
            "  clipvalue: None\n",
            "  use_ema: False\n",
            "  ema_momentum: 0.99\n",
            "  ema_overwrite_frequency: None\n",
            "  loss_scale_factor: None\n",
            "  gradient_accumulation_steps: None\n",
            "  momentum: 0.0\n",
            "  nesterov: False\n",
            "\n",
            "Model 9 Optimizer:\n",
            "  name: SGD\n",
            "  learning_rate: 0.01973462849855423\n",
            "  weight_decay: None\n",
            "  clipnorm: None\n",
            "  global_clipnorm: None\n",
            "  clipvalue: None\n",
            "  use_ema: False\n",
            "  ema_momentum: 0.99\n",
            "  ema_overwrite_frequency: None\n",
            "  loss_scale_factor: None\n",
            "  gradient_accumulation_steps: None\n",
            "  momentum: 0.0\n",
            "  nesterov: False\n",
            "\n",
            "Model 10 Optimizer:\n",
            "  name: SGD\n",
            "  learning_rate: 0.011725016869604588\n",
            "  weight_decay: None\n",
            "  clipnorm: None\n",
            "  global_clipnorm: None\n",
            "  clipvalue: None\n",
            "  use_ema: False\n",
            "  ema_momentum: 0.99\n",
            "  ema_overwrite_frequency: None\n",
            "  loss_scale_factor: None\n",
            "  gradient_accumulation_steps: None\n",
            "  momentum: 0.0\n",
            "  nesterov: False\n"
          ]
        }
      ],
      "source": [
        "# Retrieve the best model from the tuner\n",
        "top_models = tuner.get_best_models(num_models=10)\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Display summaries of the top models\n",
        "for i, model in enumerate(top_models, start=1):\n",
        "    print(f\"\\nModel {i} Summary:\")\n",
        "    model.summary()\n",
        "# Display the optimizer for each model\n",
        "for i, model in enumerate(top_models, start=1):\n",
        "    optimizer_config = model.optimizer.get_config()  # Get optimizer configuration\n",
        "    print(f\"\\nModel {i} Optimizer:\")\n",
        "    for key, value in optimizer_config.items():\n",
        "        print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8113Xh1IOK4v"
      },
      "source": [
        "If need to save the best model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "gIqeF9dEGG2N",
        "W619gwRHH3Ue",
        "ISS8LfWhNrNH"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
