{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df53505",
   "metadata": {},
   "source": [
    "# Overparametrized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c05670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from getpass import getpass\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8ce0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets_overparam.py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# reuse your raw generators\n",
    "def create_linear_dataset(n_samples=100,\n",
    "                          n_features=110,\n",
    "                          noise=0.0,\n",
    "                          random_state=None):\n",
    "    \"\"\"\n",
    "    Overparameterized linear regression dataset:\n",
    "      - X sampled U(-3, 3)\n",
    "      - y = X @ w_true + noise\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    X = rng.uniform(-3, 3, size=(n_samples, n_features))\n",
    "    w_true = rng.randn(n_features)\n",
    "    y = X.dot(w_true) + noise * rng.randn(n_samples)\n",
    "    return X.astype(np.float32), y.astype(np.float32)\n",
    "\n",
    "def create_poly_varied_dataset(n_samples=100,\n",
    "                               n_features=110,\n",
    "                               max_degree=4,\n",
    "                               noise=0.0,\n",
    "                               random_state=None):\n",
    "    \"\"\"\n",
    "    Overparameterized nonlinear regression dataset:\n",
    "      - X sampled U(-3, 3)\n",
    "      - Each feature i raised to its own degree_i ∈ [1, max_degree]\n",
    "      - y = sum_i w_true[i] * (X[:, i] ** degree_i) + noise\n",
    "    Returns:\n",
    "      X_raw, y, degrees\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    X = rng.uniform(-3, 3, size=(n_samples, n_features))\n",
    "    w_true = rng.randn(n_features)\n",
    "    degrees = rng.randint(1, max_degree + 1, size=n_features)\n",
    "    X_pow = np.stack([X[:, i] ** deg for i, deg in enumerate(degrees)], axis=1)\n",
    "    y = X_pow.dot(w_true) + noise * rng.randn(n_samples)\n",
    "    return X.astype(np.float32), y.astype(np.float32), degrees\n",
    "\n",
    "def split_data(X, y, val_size=0.2, test_size=0.2, random_state=None):\n",
    "    \"\"\"\n",
    "    Splits (X, y) into train/val/test.\n",
    "      - train: (1 - val_size - test_size)\n",
    "      - val: val_size\n",
    "      - test: test_size\n",
    "    \"\"\"\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state)\n",
    "    val_rel = val_size / (1 - test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=val_rel, random_state=random_state)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "def load_linear_data(n_samples=100,\n",
    "                     n_features=110,\n",
    "                     noise=0.0,\n",
    "                     val_size=0.2,\n",
    "                     test_size=0.2,\n",
    "                     random_state=42):\n",
    "    \"\"\"\n",
    "    Generate a linear overparam dataset and split it.\n",
    "    Returns: X_train, y_train, X_val, y_val, X_test, y_test\n",
    "    \"\"\"\n",
    "    X, y = create_linear_dataset(n_samples, n_features, noise, random_state)\n",
    "    return split_data(X, y, val_size, test_size, random_state)\n",
    "\n",
    "def load_poly_varied_data(n_samples=100,\n",
    "                          n_features=110,\n",
    "                          max_degree=4,\n",
    "                          noise=0.0,\n",
    "                          val_size=0.2,\n",
    "                          test_size=0.2,\n",
    "                          random_state=42):\n",
    "    \"\"\"\n",
    "    Generate a polynomial-varied dataset, split it, and also return degrees.\n",
    "    Returns: (X_train, y_train, X_val, y_val, X_test, y_test, degrees)\n",
    "    \"\"\"\n",
    "    X, y, degrees = create_poly_varied_dataset(\n",
    "        n_samples, n_features, max_degree, noise, random_state)\n",
    "    splits = split_data(X, y, val_size, test_size, random_state)\n",
    "    return (*splits, degrees)\n",
    "\n",
    "def create_linear_data_loader(num_workers,\n",
    "                              batch_size,\n",
    "                              worker_id,\n",
    "                              n_samples=100,\n",
    "                              n_features=110,\n",
    "                              noise=0.0,\n",
    "                              val_size=0.2,\n",
    "                              test_size=0.2,\n",
    "                              random_state=42):\n",
    "    \"\"\"\n",
    "    Return a DataLoader for a shard of the linear training set.\n",
    "    Also returns the input dimension.\n",
    "    \"\"\"\n",
    "    X_train, y_train, _, _, _, _ = load_linear_data(\n",
    "        n_samples, n_features, noise, val_size, test_size, random_state + worker_id)\n",
    "    ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "    return loader, X_train.shape[1]\n",
    "\n",
    "def create_poly_varied_data_loader(num_workers,\n",
    "                                   batch_size,\n",
    "                                   worker_id,\n",
    "                                   n_samples=100,\n",
    "                                   n_features=110,\n",
    "                                   max_degree=4,\n",
    "                                   noise=0.0,\n",
    "                                   val_size=0.2,\n",
    "                                   test_size=0.2,\n",
    "                                   random_state=42):\n",
    "    \"\"\"\n",
    "    Return a DataLoader for a shard of the poly-varied training set.\n",
    "    Also returns the input dimension (same as n_features).\n",
    "    \"\"\"\n",
    "    X_train, y_train, _, _, _, _, degrees = load_poly_varied_data(\n",
    "        n_samples, n_features, max_degree, noise, val_size, test_size, random_state + worker_id)\n",
    "    ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "    return loader, X_train.shape[1], degrees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75e1934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For linear dataset \n",
    "\n",
    "# full splits\n",
    "X_tr, y_tr, X_val, y_val, X_te, y_te = load_linear_data(\n",
    "    n_samples=101, n_features=110, noise=0.0,val_size=0.01,test_size=0.2, random_state=42 )\n",
    "\n",
    "# single-worker loader\n",
    "loader, dim = create_linear_data_loader(\n",
    "    num_workers=1, batch_size=32, worker_id=0,\n",
    "    n_samples=200, n_features=50, noise=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e54454b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear shapes: [(79, 110), (79,), (1, 110), (1,), (20, 110), (20,)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Polynomial-varied dataset\\nX_poly, y_poly, degrees = create_poly_varied_dataset(\\n    n_samples=100, n_features=110, max_degree=4, noise=0.0, random_state=42)\\npoly_splits = split_data(X_poly, y_poly, val_size=0.01, test_size=0.2, random_state=42)  # Overparametrized cases always converge to 0 loss so no need for hyperparameter search!\\nprint(\"Poly-varied shapes:\", [arr.shape for arr in poly_splits])\\nprint(\"Sample feature degrees:\", degrees[:10])\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# OVERPARAMETERIZED DATASETS WITH FEATURE BOUNDS [-3, 3]\n",
    "#\n",
    "# Features X are sampled uniformly in [-3, 3], ensuring all inputs\n",
    "# lie within the specified bounds before any polynomial transformations.\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def create_linear_dataset(n_samples=100, n_features=110, noise=0.0, random_state=None): #Currently noise set to 0\n",
    "    \"\"\"\n",
    "    Overparameterized linear regression dataset:\n",
    "      - X sampled U(-3, 3)\n",
    "      - y = X @ w_true + noise\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    X = rng.uniform(low=-3, high=3, size=(n_samples, n_features))\n",
    "    w_true = rng.randn(n_features)\n",
    "    y = X.dot(w_true) + noise * rng.randn(n_samples)\n",
    "    return X, y\n",
    "\n",
    "def create_poly_varied_dataset(n_samples=100, n_features=110,\n",
    "                               max_degree=4, noise=0.0, random_state=None): #Currently noise set to 0\n",
    "    \"\"\"\n",
    "    Overparameterized nonlinear regression dataset:\n",
    "      - X sampled U(-3, 3)\n",
    "      - Each feature i raised to its own degree_i ∈ [1, max_degree]\n",
    "      - y = sum_i w_true[i] * (X[:,i] ** degree_i) + noise\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    X = rng.uniform(low=-3, high=3, size=(n_samples, n_features))\n",
    "    w_true = rng.randn(n_features)\n",
    "    degrees = rng.randint(1, max_degree + 1, size=n_features)\n",
    "    X_pow = np.zeros_like(X)\n",
    "    for i, d in enumerate(degrees):\n",
    "        X_pow[:, i] = X[:, i] ** d\n",
    "    y = X_pow.dot(w_true) + noise * rng.randn(n_samples)\n",
    "    return X, y, degrees\n",
    "\n",
    "def split_data(X, y, val_size=0.2, test_size=0.2, random_state=None):\n",
    "    \"\"\"\n",
    "    Splits data into train (60%), validation (20%), and test (20%) sets.\n",
    "    \"\"\"\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state)\n",
    "    val_rel = val_size / (1 - test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=val_rel, random_state=random_state)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# ------------------------------\n",
    "# Example: generate & split both\n",
    "# ------------------------------\n",
    "# Linear dataset\n",
    "X_lin, y_lin = create_linear_dataset(n_samples=100, n_features=110, noise=0.0,random_state=42)\n",
    "lin_splits = split_data(X_lin, y_lin, val_size=0.01, test_size=0.2, random_state=42) # Overparametrized cases always converge to 0 loss so no need for hyperparameter search!\n",
    "print(\"Linear shapes:\", [arr.shape for arr in lin_splits])\n",
    "\n",
    "\n",
    "# Polynomial-varied dataset\n",
    "X_poly, y_poly, degrees = create_poly_varied_dataset(\n",
    "    n_samples=100, n_features=110, max_degree=4, noise=0.0, random_state=42)\n",
    "poly_splits = split_data(X_poly, y_poly, val_size=0.01, test_size=0.2, random_state=42)  # Overparametrized cases always converge to 0 loss so no need for hyperparameter search!\n",
    "print(\"Poly-varied shapes:\", [arr.shape for arr in poly_splits])\n",
    "print(\"Sample feature degrees:\", degrees[:10])\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9aed1f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import svd\n",
    "\n",
    "#X_tr_lin, y_tr_lin, X_val_lin, y_val_lin, X_te_lin, y_te_lin = lin_splits\n",
    "X_tr_lin, y_tr_lin, X_val_lin, y_val_lin, X_te_lin, y_te_lin = X_tr, y_tr, X_val, y_val, X_te, y_te\n",
    "X_comb = np.vstack([X_tr_lin, X_val_lin])\n",
    "y_comb = np.concatenate([y_tr_lin, y_val_lin])\n",
    "n, d = X_comb.shape\n",
    "rng = np.random.RandomState(42)\n",
    "scale = 5   # avoids huge outliers\n",
    "# Amount of initializations\n",
    "init_ws = rng.uniform(-scale, scale, size=(1, d))\n",
    "np.save('linear_init_weights.npy', init_ws)\n",
    "\n",
    "# 3) Compute 95% of max stable step size η₉₅\n",
    "_, S_comb, _ = svd(X_comb, full_matrices=False)\n",
    "eta_max = 2.0 / (S_comb[0]**2)\n",
    "eta_95  = 0.95 * eta_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2e0ea3",
   "metadata": {},
   "source": [
    "# Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35c6648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import multiprocessing as mp\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class ConfigParameters:\n",
    "    \"\"\"\n",
    "    Configuration for Stale Synchronous Parallel training for Asynchronous SGD (SSP-ASGD).\n",
    "\n",
    "    :param num_workers: Number of worker processes.\n",
    "    :type num_workers: int\n",
    "    :param staleness: Staleness bound allowed for the workers during training. Represents the maximum number of versions a worker can be behind the latest version.\n",
    "    :type staleness: int\n",
    "    :param lr: Learning rate for the model. Represents the step size for updating the model parameters.\n",
    "    :type lr: float\n",
    "    :param local_steps: Number of steps/updates each worker locally computes before pushing gradients to the server.\n",
    "    :type local_steps: int\n",
    "    :param batch_size: Batch size for each training step and the data loader.\n",
    "    :type batch_size: int\n",
    "    :param device: Device to use for training (e.g., \"cuda\" or \"cpu\").\n",
    "    :type device: str\n",
    "    :param log_level: Logging verbosity level.\n",
    "    :type log_level: int\n",
    "    \"\"\"\n",
    "    num_workers: int = 4\n",
    "    staleness: int = 2\n",
    "    lr: float  = eta_95 # HAS TO BE CHANGED TO GUARANTEE CONVERGENCE \n",
    "    local_steps: int = 500 #?\n",
    "    batch_size: int = 32\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    log_level: int = logging.INFO\n",
    "\n",
    "class ParameterServer:\n",
    "    \"\"\"\n",
    "    Parameter Server for Stale Synchronous Parallel training. \n",
    "    The server manages the global model parameters and coordinates the gradient updates from multiple workers.\n",
    "    Each worker computes gradients locally and with a `push` operation sends the result to the server, which aggregates the gradients and updates the model parameters.\n",
    "    Each worker can receive the latest model parameters with a `pull` operation.\n",
    "    \n",
    "    Arguments:\n",
    "    :param model: PyTorch model instance \n",
    "    :type model: nn.Module\n",
    "    :param param: Configuration parameters\n",
    "    :type param: ConfigParameters\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: nn.Module, param: ConfigParameters) -> None:\n",
    "        self.param = param\n",
    "\n",
    "        # Define a list with the global model parameters shared among all workers\n",
    "        self.theta = [p.detach() for p in model.parameters()]\n",
    "        for p in self.theta:\n",
    "            p.share_memory_() # Parameters are stored in a shared memory among all workers\n",
    "\n",
    "        # Lock and Multiprocessing condition variable for synchronization\n",
    "        # For safe access access to shared resources\n",
    "        self._lock = mp.Lock() \n",
    "        self._cv = mp.Condition(self._lock)\n",
    "\n",
    "        # Shared integer for the current global version\n",
    "        self._current_version = mp.Value(\"i\", 0)\n",
    "\n",
    "        # Shared array of integers for the current versions of each worker\n",
    "        self._worker_versions = mp.Array(\"i\", [0]*param.num_workers)\n",
    "\n",
    "        # Multiprocessing Manager object to manage shared objects\n",
    "        self.manager = mp.Manager()\n",
    "        # Shared dictionary to store pending gradients pushed by workers\n",
    "        self._pending = self.manager.dict()\n",
    "\n",
    "    def pull(self) -> Tuple[list[torch.Tensor], int]:\n",
    "        \"\"\"\n",
    "        Fetch the current model parameters and the current version from the server.\n",
    "        This method is called by the workers to get the latest model parameters before starting their local training or when they need to synchronize with the server.\n",
    "        \n",
    "        :return: A tuple containing the current model parameters and the current version.\n",
    "        :rtype: Tuple[list[torch.Tensor], int]\n",
    "        \"\"\"\n",
    "        with self._lock:\n",
    "            return [p.clone() for p in self.theta], self._current_version.value\n",
    "\n",
    "    def push(self, wid: int, version: int, grads: list[torch.Tensor]) -> None:\n",
    "        \"\"\"\n",
    "        Push the gradients computed by a worker to the server for later aggregation.\n",
    "        This method is called by the workers after they have computed gradients locally.\n",
    "        If all workers have pushed their gradients for the same version, the server will aggregate them and update the model parameters.\n",
    "        The server will notify all workers when the aggregation is complete.\n",
    "\n",
    "        :param wid: Worker ID of the worker pushing the gradients.\n",
    "        :type wid: int\n",
    "        :param version: Current version of the model parameters.\n",
    "        :type version: int\n",
    "        :param grads: List of gradients computed by the worker.\n",
    "        :type grads: list[torch.Tensor]\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "\n",
    "        with self._lock:\n",
    "            grads_np = [grad.cpu().numpy() for grad in grads] # Convert gradients to numpy arrays\n",
    "\n",
    "            # Store the gradients in the shared dictionary of pending gradient updates\n",
    "            key = (version, wid) # the key is a tuple of the update version and worker ID\n",
    "            self._pending[key] = grads_np \n",
    "\n",
    "            # Check if all workers have pushed their gradients for this version\n",
    "            if sum(1 for key in self._pending.keys() if key[0] == version) == self.param.num_workers:\n",
    "                \n",
    "                # Aggregate all the gradients the worker pushed for this version\n",
    "                aggregated_grad = []\n",
    "                for i in range(len(grads)):\n",
    "                    grad_list = [self._pending[(version, id)][i] for id in range(self.param.num_workers)]\n",
    "                    avg_grad = np.mean(grad_list, axis=0)\n",
    "                    aggregated_grad.append(torch.from_numpy(avg_grad).to(device=self.theta[i].device))\n",
    "\n",
    "                # Update the model parameters with the aggregated gradients\n",
    "                for idx, avg_grad in enumerate(aggregated_grad):\n",
    "                    self.theta[idx].sub_(self.param.lr * avg_grad)\n",
    "                \n",
    "                # Remove the pending gradients for this version from the shared dictionary\n",
    "                for w in range(self.param.num_workers):\n",
    "                    del self._pending[(version, w)]\n",
    "\n",
    "                # Notify all workers that the global value for this version is computed\n",
    "                self._current_version.value = version\n",
    "                self._cv.notify_all()\n",
    "\n",
    "    def get_version(self) -> int:\n",
    "        \"\"\"\n",
    "        Get current global version.\n",
    "        \n",
    "        :return: The current version of the model parameters.\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "\n",
    "        # A lock can be avoided as in worst case a worker will get a previous value and \n",
    "        # therefore wait (but even with the lock a process will wait).\n",
    "        # with self._lock:\n",
    "        return self._current_version.value\n",
    "\n",
    "def worker(\n",
    "    w_id: int,\n",
    "    server:  ParameterServer,\n",
    "    model: Callable[[int], nn.Module],\n",
    "    input_dim:  int,\n",
    "    dataset_builder: Callable[[int,int,int], Tuple[torch.utils.data.DataLoader,int]],\n",
    "    param: ConfigParameters\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Worker function for Stale Synchronous Parallel training.\n",
    "\n",
    "    :param w_id: Worker ID.\n",
    "    :type w_id: int\n",
    "    :param server: Parameter server\n",
    "    :type server: ParameterServer\n",
    "    :param model: Model class to be trained.\n",
    "    :type model: Callable[[int], nn.Module]\n",
    "    :param input_dim: Input dimension of the model.\n",
    "    :type input_dim: int\n",
    "    :param dataset_builder: Function used to build the dataset.\n",
    "    :type dataset_builder: Callable[[int,int,int], Tuple[torch.utils.data.DataLoader,int]]+\n",
    "    :param param: SSP Configuration parameters.\n",
    "    :type param: ConfigParameters\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # Basic logging configuration\n",
    "    logging.basicConfig(\n",
    "        level=param.log_level,\n",
    "        format=f\"%(asctime)s [Worker-{w_id}] %(message)s\",\n",
    "        datefmt=\"%H:%M:%S\",\n",
    "    )\n",
    "\n",
    "    # Data loader from the dataset builder and the model parameters\n",
    "    # Dataset contains an unique subset of data for each worker (changing `random_state` parameter)\n",
    "    loader, _ = dataset_builder(param.num_workers, param.batch_size, w_id)\n",
    "\n",
    "    # Create the model and loss function\n",
    "    device = torch.device(param.device)\n",
    "    model = model(input_dim).to(device)\n",
    "    #criterion = nn.BCELoss() # Binary Cross Entropy Loss for binary classification\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Initialize the model parameters by retrieving the global model parameters from the server\n",
    "    state, version = server.pull()\n",
    "    with torch.no_grad():\n",
    "        for p, s in zip(model.parameters(), state):\n",
    "            p.copy_(s.to(device))\n",
    "    \n",
    "    # Define the local version and last checked remote version for staleness\n",
    "    local_ver = version\n",
    "    last_check = version    \n",
    "\n",
    "    # Run the local updates and push updates to the server\n",
    "    for step in range(param.local_steps):\n",
    "\n",
    "        # Each step is a full loop over the loaded portion of dataset\n",
    "        for X_batch, y_batch in loader:\n",
    "            # For each mini-batch from the worker's own data subset:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            model.train()\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch.float())\n",
    "            loss.backward()\n",
    "\n",
    "            # Collect gradients and store them on CPU tensors\n",
    "            grads = [p.grad.detach().cpu() for p in model.parameters()]\n",
    "            for p in model.parameters():\n",
    "                p.grad = None # Clear gradients to avoid accumulation in the next step\n",
    "            \n",
    "            # Obey to the staleness constraint by syncronizing with the server version and \n",
    "            # updating the local model parameters if needed. \n",
    "            while (local_ver - last_check) > param.staleness:\n",
    "                last_check = server.get_version()\n",
    "                state, g_ver = server.pull()\n",
    "                with torch.no_grad():\n",
    "                    for p, s in zip(model.parameters(), state):\n",
    "                        p.copy_(s.to(device))\n",
    "                local_ver = g_ver\n",
    "\n",
    "            # Update local version and push the gradients to the server\n",
    "            local_ver += 1\n",
    "            server.push(w_id, local_ver, grads)\n",
    "\n",
    "def run_ssp_training(\n",
    "    dataset_builder: Callable[[int, int,int], Tuple[torch.utils.data.DataLoader,int]],\n",
    "    model: Callable[[int], nn.Module],\n",
    "    param: ConfigParameters = ConfigParameters(),\n",
    ") -> list[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Helper function to run the Stale Synchronous Parallel training with the provided dataset builder, model and configuration parameters.\n",
    "\n",
    "    :param dataset_builder: Function used to build the dataset.\n",
    "    :param model: Model class to be trained.\n",
    "    :param param: SSP Configuration parameters.\n",
    "    :type param: ConfigParameters\n",
    "    :return: The final model parameters after training.\n",
    "    :rtype: list[torch.Tensor]\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve input dimension from dataset builder with provided batch size and number of workers\n",
    "    _, input_dim = dataset_builder(param.num_workers, param.batch_size, 0)\n",
    "\n",
    "    # Initialize the model and parameter server\n",
    "    init_model = model(input_dim)\n",
    "    ps = ParameterServer(init_model, param)\n",
    "\n",
    "    # Create a process for each worker\n",
    "    # Use either \"fork\" or \"spawn\" based on your OS (\"fork\" on Linux)\n",
    "    ctx = mp.get_context(\"spawn\") # Context for multiprocessing\n",
    "    procs = [] # List to hold the processes\n",
    "    for id in range(param.num_workers):\n",
    "        p = ctx.Process(\n",
    "            target=worker, # Worker function\n",
    "            args=(id, ps, model, input_dim, dataset_builder, param), # Arguments for the worker function\n",
    "            daemon=False, # Daemon processes are not used as they are killed when the main process exits\n",
    "        )\n",
    "        p.start() # Start the worker process\n",
    "        procs.append(p) # Append the process to the list\n",
    "\n",
    "    for p in procs:\n",
    "        p.join() # Wait for all processes to finish\n",
    "        if p.exitcode != 0: # Check if the process exited with an error\n",
    "            raise RuntimeError(f\"Worker {p.name} crashed (exitcode {p.exitcode})\")\n",
    "\n",
    "\n",
    "    theta, _ = ps.pull() # Get the final parameter theta from the server\n",
    "\n",
    "    #print(\"Final Version: \", ps.get_version())\n",
    "    #logging.info(\"SSP training finished\")\n",
    "\n",
    "    return theta, input_dim\n",
    "\n",
    "def build_model(theta: list[torch.Tensor], model, input_dim: int) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Build a model instance from the provided parameters.\n",
    "\n",
    "    :param theta: List of model parameters.\n",
    "    :type theta: list[torch.Tensor]\n",
    "    :param model_cls: Model class to be instantiated.\n",
    "    :type model_cls: Callable[[int], nn.Module]\n",
    "    :param input_dim: Input dimension of the model.\n",
    "    :type input_dim: int\n",
    "    :return: Model instance with the provided parameters.\n",
    "    :rtype: nn.Module\n",
    "    \"\"\"\n",
    "    model = model(input_dim)\n",
    "    with torch.no_grad():\n",
    "        for param, trained_param in zip(model.parameters(), theta):\n",
    "            param.copy_(trained_param)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(name:str, model: nn.Module, X_eval: np.ndarray, y_eval: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate the model on the provided evaluation dataset.\n",
    "\n",
    "    :param model: Model instance to be evaluated.\n",
    "    :type model: nn.Module\n",
    "    :param X_eval: Evaluation dataset features.\n",
    "    :type X_eval: np.ndarray\n",
    "    :param y_eval: Evaluation dataset labels.\n",
    "    :type y_eval: np.ndarray\n",
    "    :return: Accuracy of the model on the evaluation dataset.\n",
    "    :rtype: float\n",
    "    :raises ValueError: If the model is not in evaluation mode.\n",
    "    \"\"\"\n",
    "    # ensure in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # Move data into torch tensors\n",
    "    X_tensor = torch.from_numpy(X_eval).float()\n",
    "    y_tensor = torch.from_numpy(y_eval).float()\n",
    "\n",
    "    # For MSE, use the built‑in loss (mean reduction by default)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        y_pred = model(X_tensor)\n",
    "\n",
    "        # If model outputs extra dims, flatten to match y_eval\n",
    "        # e.g. y_pred = y_pred.view_as(y_tensor)\n",
    "\n",
    "        # Compute MSE\n",
    "        mse = criterion(y_pred, y_tensor).item()\n",
    "\n",
    "    print(f\"{name} Test MSE = {mse:.6f}\")\n",
    "    return mse\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2be555",
   "metadata": {},
   "source": [
    "***TRAINING***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d823e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ssp.py\n",
    "import logging\n",
    "import torch\n",
    "from async_ssp import run_ssp_training, ConfigParameters\n",
    "from datasets import create_adult_dataset\n",
    "from model import LinearNetModel\n",
    "from datasets import load_adult_data\n",
    "from async_ssp import nn\n",
    "from async_ssp import evaluate_model, build_model\n",
    "import time\n",
    "\n",
    "def sgd_training(num_epochs = 10000, criterion = nn.MSELoss(), batch_size = 32, lr = eta_95, tol=1e-8):\n",
    "    X_train, y_train = X_comb, y_comb \n",
    "\n",
    "    # Create a linear model with dimention equal to the number of features\n",
    "    # in the dataset\n",
    "    model   = LinearNetModel(X_train.shape[1])\n",
    "\n",
    "    # Train the model using standard SGD\n",
    "    loader  = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(\n",
    "           torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "        ),\n",
    "        batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "\n",
    "        # Iterate over the batches of training data\n",
    "        for Xb, yb in loader:\n",
    "            optimizer.zero_grad() # Reset the gradients\n",
    "            out  = model(Xb) # Forward pass\n",
    "            loss = criterion(out, yb.float()) # Compute the loss\n",
    "            loss.backward() # Backward pass\n",
    "            optimizer.step() # Update the model parameters\n",
    "            total_epoch_loss += loss.item() # Accumulate the loss\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_loss = total_epoch_loss / num_batches\n",
    "        # Print every 1000 epochs\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f\"[Epoch {epoch:5d}] Avg Loss = {avg_loss:.6f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_loss < tol:\n",
    "            print(f\"Stopping early at epoch {epoch} with avg loss {avg_loss:.6f} < tol={tol}\")\n",
    "            break\n",
    "\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    # Set up logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    # Set up the configuration for the SSP training\n",
    "    params_ssp = ConfigParameters(\n",
    "        num_workers = 2,\n",
    "        staleness = 10,\n",
    "        lr = eta_95,\n",
    "        local_steps = 5,\n",
    "        batch_size = 32,\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        log_level = logging.DEBUG,\n",
    "    )\n",
    "\n",
    "    # Dataset builder function\n",
    "    #dataset_builder = create_adult_dataset\n",
    "    dataset_builder = create_linear_data_loader\n",
    "    # Model class\n",
    "    model = LinearNetModel\n",
    "\n",
    "    # Run the SSP training and measure the time taken\n",
    "    start = time.perf_counter()\n",
    "    ctx = mp.get_context(\"spawn\")\n",
    "    asgd_params, dim = run_ssp_training(dataset_builder, model, params_ssp)\n",
    "    end = time.perf_counter()\n",
    "    asgd_time = end - start\n",
    "\n",
    "    # Evaluate the trained model on the test set\n",
    "    _, X_test, _, y_test = load_adult_data()\n",
    "    asgd_model = build_model(asgd_params, model, dim)\n",
    "    evaluate_model(\"ASGD\", asgd_model, X_te_lin, y_te_lin)\n",
    "\n",
    "    # run baseline for comparison\n",
    "    start = time.perf_counter()\n",
    "    sgd_model = sgd_training()\n",
    "    end = time.perf_counter()\n",
    "    sgd_time = end-start\n",
    "\n",
    "    evaluate_model(\"SGD\", sgd_model, X_te_lin, y_te_lin)\n",
    "\n",
    "    print(f\"Time Comparison: ASGD {asgd_time:2f} sec;\\tSGD {sgd_time:2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4565c9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot find context for 'fork'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 78\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     76\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m     77\u001b[0m ctx \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mget_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 78\u001b[0m asgd_params, dim \u001b[38;5;241m=\u001b[39m \u001b[43mrun_ssp_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_builder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_ssp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m     80\u001b[0m asgd_time \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\caspa\\OneDrive\\Bureaublad\\Semester2 (EPFL)\\Optimization for ML\\Project\\ASGD\\optML_mini_project\\SSP_ASGD\\async_ssp.py:252\u001b[0m, in \u001b[0;36mrun_ssp_training\u001b[1;34m(dataset_builder, model, param)\u001b[0m\n\u001b[0;32m    248\u001b[0m ps \u001b[38;5;241m=\u001b[39m ParameterServer(init_model, param)\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# Create a process for each worker\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# Use either \"fork\" or \"spawn\" based on your OS (\"fork\" on Linux)\u001b[39;00m\n\u001b[1;32m--> 252\u001b[0m ctx \u001b[38;5;241m=\u001b[39m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfork\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Context for multiprocessing\u001b[39;00m\n\u001b[0;32m    253\u001b[0m procs \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m# List to hold the processes\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(param\u001b[38;5;241m.\u001b[39mnum_workers):\n",
      "File \u001b[1;32mc:\\Users\\caspa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:239\u001b[0m, in \u001b[0;36mDefaultContext.get_context\u001b[1;34m(self, method)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actual_context\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\caspa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:193\u001b[0m, in \u001b[0;36mBaseContext.get_context\u001b[1;34m(self, method)\u001b[0m\n\u001b[0;32m    191\u001b[0m     ctx \u001b[38;5;241m=\u001b[39m _concrete_contexts[method]\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcannot find context for \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m method) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    194\u001b[0m ctx\u001b[38;5;241m.\u001b[39m_check_available()\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ctx\n",
      "\u001b[1;31mValueError\u001b[0m: cannot find context for 'fork'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
